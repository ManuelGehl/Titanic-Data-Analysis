{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhR_lp41-aLY"
   },
   "source": [
    "# Model building for survival prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AB36BPmAVQGA",
    "outputId": "28478c03-de4f-4994-92ad-1494e6a58ed8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Set default style for graphs\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "gQcM7gq1VQGI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import datasets\n",
    "test_dataset = pd.read_csv(\"Datasets/test.csv\")\n",
    "train_dataset = pd.read_csv(\"Datasets/train.csv\")\n",
    "test_dataset_copy = test_dataset.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oEBDL31VQGX"
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUdAD6iSIryR"
   },
   "source": [
    "### Split data into features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lLOo8f9WJjub",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separate features from labels\n",
    "X_train = train_dataset.drop(\"Survived\", axis=1)\n",
    "y_train = train_dataset[\"Survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qOcq6-_VQGX"
   },
   "source": [
    "### Transformations\n",
    "\n",
    "1. Drop PassengerId, Ticket, Cabin and Name\n",
    "2. Impute numerical columns with mean and categorical columns with most frequent\n",
    "3. Combine number of parents/children and siblings/spouses into new category \"Relatives\"\n",
    "4. Divide the relatives into 3 bins [0, 1-3, >3]\n",
    "5. Age is divided into 2 categories: age 0-10 and >10\n",
    "6. Numerical features are scaled (default StandardScaler)\n",
    "7. Categorical features are one-hot encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yeoj8Nj_rHXF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def titanic_transformation(dataset:pd.DataFrame, scaler=StandardScaler()) -> pd.DataFrame:\n",
    "  \"\"\"\n",
    "  Processes the dataset according to the following steps:\n",
    "    1. Drops PassengerId, Ticket, Cabin and Name\n",
    "    2. Impute numerical columns with mean\n",
    "       and categorical columns with most frequent\n",
    "    3. Combines number of parents/children and siblings/spouses\n",
    "       into new category \"Relatives\"\n",
    "    4. Divides the relatives into 3 bins [0, 1-3, >3]\n",
    "    5. Age is divided into 2 categories: age 0-10 and >10\n",
    "    6. Numerical features are scaled (default StandardScaler)\n",
    "    7. Categorical features are one-hot encoded\n",
    "\n",
    "  Returns: Dataframe\n",
    "\n",
    "  Args: - dataset: dataframe for transformation\n",
    "        - scaler: scaler for numerical features\n",
    "\n",
    "  \"\"\"\n",
    "  # Drop PassengerId\n",
    "  dataset.drop([\"PassengerId\", \"Ticket\", \"Cabin\", \"Name\"], axis=1, inplace=True)\n",
    "\n",
    "  # Define columns for different transformations\n",
    "  numerical_columns = [\"Age\", \"Fare\"]\n",
    "  categorical_columns = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\"]\n",
    "\n",
    "  # Impute first missing values\n",
    "  original_columns = dataset.columns.to_list() # Save column names\n",
    "  imputer_num = Pipeline([(\"imputer_num\", SimpleImputer(strategy=\"mean\"))])\n",
    "  imputer_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy=\"most_frequent\"))])\n",
    "  imputer = ColumnTransformer(\n",
    "      transformers=[\n",
    "          (\"imputer_num\", imputer_num, numerical_columns),\n",
    "          (\"imputer_cat\", imputer_cat, categorical_columns)\n",
    "          ], remainder=\"passthrough\")\n",
    "  dataset = imputer.fit_transform(dataset)\n",
    "  dataset = pd.DataFrame(dataset,\n",
    "                         columns=imputer.get_feature_names_out())\n",
    "\n",
    "  # Combine Parch and SibSp into relatives\n",
    "  dataset[\"Relatives\"] = dataset[\"imputer_cat__Parch\"] + dataset[\"imputer_cat__SibSp\"]\n",
    "\n",
    "  # Separate relatives into 3 categories: alone, 1-3, >3\n",
    "  bin_edges = [-1, 0, 3, float(\"inf\")]\n",
    "  bin_labels = [\"0 relatives\", \"1-3 relatives\", \">3 relatives\"]\n",
    "  dataset[\"Relative_cat\"] = pd.cut(dataset[\"Relatives\"],\n",
    "                                   bins=bin_edges,\n",
    "                                   labels=bin_labels)\n",
    "\n",
    "   # Separate age into 2 categories: <15, >15\n",
    "  bin_edges = [-1, 15, float(\"inf\")]\n",
    "  bin_labels = [\"0-15\", \">15\"]\n",
    "  dataset[\"Age_cat\"] = pd.cut(dataset[\"imputer_num__Age\"],\n",
    "                              bins=bin_edges,\n",
    "                              labels=bin_labels)\n",
    "\n",
    "  # Create transformers for each type of transformation\n",
    "  numerical_scaler = Pipeline([(\"scaler\", scaler)])\n",
    "  categorical_encoder = Pipeline([(\"onehot\", OneHotEncoder(drop=\"first\",\n",
    "                                                           sparse_output=False)\n",
    "  )])\n",
    "\n",
    " # Add new features to feature lists\n",
    "  numerical_columns = [\"imputer_num__Age\", \"imputer_num__Fare\",\"Relatives\",\n",
    "                       \"imputer_cat__SibSp\", \"imputer_cat__Parch\"]\n",
    "  categorical_columns = [\"imputer_cat__Pclass\", \"imputer_cat__Sex\",\n",
    "                         \"imputer_cat__Embarked\",\n",
    "                         \"Relative_cat\", \"Age_cat\"]\n",
    "\n",
    "  # Create a ColumnTransformer to apply transformations to the respective columns\n",
    "  preprocessor = ColumnTransformer(\n",
    "      transformers=[\n",
    "          (\"num\", numerical_scaler, numerical_columns),\n",
    "           (\"cat\", categorical_encoder, categorical_columns)]\n",
    "      ,remainder=\"passthrough\")\n",
    "\n",
    "  # Transform dataset\n",
    "  dataset = preprocessor.fit_transform(dataset)\n",
    "  dataset = pd.DataFrame(dataset,\n",
    "                         columns=preprocessor.get_feature_names_out())\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "4Oj7bTdzteRm",
    "outputId": "e9e23b9f-3c44-414c-8b10-44d2d67851e1",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__imputer_num__Age</th>\n",
       "      <th>num__imputer_num__Fare</th>\n",
       "      <th>num__Relatives</th>\n",
       "      <th>num__imputer_cat__SibSp</th>\n",
       "      <th>num__imputer_cat__Parch</th>\n",
       "      <th>cat__imputer_cat__Pclass_2</th>\n",
       "      <th>cat__imputer_cat__Pclass_3</th>\n",
       "      <th>cat__imputer_cat__Sex_male</th>\n",
       "      <th>cat__imputer_cat__Embarked_Q</th>\n",
       "      <th>cat__imputer_cat__Embarked_S</th>\n",
       "      <th>cat__Relative_cat_1-3 relatives</th>\n",
       "      <th>cat__Relative_cat_&gt;3 relatives</th>\n",
       "      <th>cat__Age_cat_&gt;15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.592481</td>\n",
       "      <td>-0.502445</td>\n",
       "      <td>0.059160</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.638789</td>\n",
       "      <td>0.786845</td>\n",
       "      <td>0.059160</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.284663</td>\n",
       "      <td>-0.488854</td>\n",
       "      <td>-0.560975</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.407926</td>\n",
       "      <td>0.420730</td>\n",
       "      <td>0.059160</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.407926</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>-0.560975</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>-0.207709</td>\n",
       "      <td>-0.386671</td>\n",
       "      <td>-0.560975</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>-0.823344</td>\n",
       "      <td>-0.044381</td>\n",
       "      <td>-0.560975</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.176263</td>\n",
       "      <td>1.299429</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>2.008933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>-0.284663</td>\n",
       "      <td>-0.044381</td>\n",
       "      <td>-0.560975</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.177063</td>\n",
       "      <td>-0.492378</td>\n",
       "      <td>-0.560975</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     num__imputer_num__Age  num__imputer_num__Fare  num__Relatives  \\\n",
       "0                -0.592481               -0.502445        0.059160   \n",
       "1                 0.638789                0.786845        0.059160   \n",
       "2                -0.284663               -0.488854       -0.560975   \n",
       "3                 0.407926                0.420730        0.059160   \n",
       "4                 0.407926               -0.486337       -0.560975   \n",
       "..                     ...                     ...             ...   \n",
       "886              -0.207709               -0.386671       -0.560975   \n",
       "887              -0.823344               -0.044381       -0.560975   \n",
       "888               0.000000               -0.176263        1.299429   \n",
       "889              -0.284663               -0.044381       -0.560975   \n",
       "890               0.177063               -0.492378       -0.560975   \n",
       "\n",
       "     num__imputer_cat__SibSp  num__imputer_cat__Parch  \\\n",
       "0                   0.432793                -0.473674   \n",
       "1                   0.432793                -0.473674   \n",
       "2                  -0.474545                -0.473674   \n",
       "3                   0.432793                -0.473674   \n",
       "4                  -0.474545                -0.473674   \n",
       "..                       ...                      ...   \n",
       "886                -0.474545                -0.473674   \n",
       "887                -0.474545                -0.473674   \n",
       "888                 0.432793                 2.008933   \n",
       "889                -0.474545                -0.473674   \n",
       "890                -0.474545                -0.473674   \n",
       "\n",
       "     cat__imputer_cat__Pclass_2  cat__imputer_cat__Pclass_3  \\\n",
       "0                           0.0                         1.0   \n",
       "1                           0.0                         0.0   \n",
       "2                           0.0                         1.0   \n",
       "3                           0.0                         0.0   \n",
       "4                           0.0                         1.0   \n",
       "..                          ...                         ...   \n",
       "886                         1.0                         0.0   \n",
       "887                         0.0                         0.0   \n",
       "888                         0.0                         1.0   \n",
       "889                         0.0                         0.0   \n",
       "890                         0.0                         1.0   \n",
       "\n",
       "     cat__imputer_cat__Sex_male  cat__imputer_cat__Embarked_Q  \\\n",
       "0                           1.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           1.0                           0.0   \n",
       "..                          ...                           ...   \n",
       "886                         1.0                           0.0   \n",
       "887                         0.0                           0.0   \n",
       "888                         0.0                           0.0   \n",
       "889                         1.0                           0.0   \n",
       "890                         1.0                           1.0   \n",
       "\n",
       "     cat__imputer_cat__Embarked_S  cat__Relative_cat_1-3 relatives  \\\n",
       "0                             1.0                              1.0   \n",
       "1                             0.0                              1.0   \n",
       "2                             1.0                              0.0   \n",
       "3                             1.0                              1.0   \n",
       "4                             1.0                              0.0   \n",
       "..                            ...                              ...   \n",
       "886                           1.0                              0.0   \n",
       "887                           1.0                              0.0   \n",
       "888                           1.0                              1.0   \n",
       "889                           0.0                              0.0   \n",
       "890                           0.0                              0.0   \n",
       "\n",
       "     cat__Relative_cat_>3 relatives  cat__Age_cat_>15  \n",
       "0                               0.0               1.0  \n",
       "1                               0.0               1.0  \n",
       "2                               0.0               1.0  \n",
       "3                               0.0               1.0  \n",
       "4                               0.0               1.0  \n",
       "..                              ...               ...  \n",
       "886                             0.0               1.0  \n",
       "887                             0.0               1.0  \n",
       "888                             0.0               1.0  \n",
       "889                             0.0               1.0  \n",
       "890                             0.0               1.0  \n",
       "\n",
       "[891 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform all datasets\n",
    "X_train_transformed = titanic_transformation(X_train)\n",
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0v9h4yJhekW"
   },
   "source": [
    "### Divide the dataset into subsets to screen features for different models\n",
    "\n",
    "* Base: Fare (continuous), Pclass (categorical), Sex (categorical), Embarked (categorical)\n",
    "* Subset 1: Age (continuous), Relatives(continuous)\n",
    "* Subset 2: Age (categorical younger and older than 15), Relatives (3 classes)\n",
    "* Subset 3: Parch (continuous), SibSp (continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TdvmYxAChbPa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Divide dataset into subsets for feature screening\n",
    "base_set_columns = [\"num__imputer_num__Fare\", \"cat__imputer_cat__Pclass_2\",\n",
    "                    \"cat__imputer_cat__Pclass_3\", \"cat__imputer_cat__Sex_male\",\n",
    "                    'cat__imputer_cat__Embarked_Q', 'cat__imputer_cat__Embarked_S']\n",
    "subset_1_columns = [\"num__imputer_num__Age\", \t\"num__imputer_num__Fare\",\n",
    "                    \"cat__imputer_cat__Pclass_2\", \t\"cat__imputer_cat__Pclass_3\",\n",
    "                    \"cat__imputer_cat__Sex_male\", 'cat__imputer_cat__Embarked_Q',\n",
    "                    'cat__imputer_cat__Embarked_S',\"num__Relatives\"]\n",
    "subset_2_columns = ['num__imputer_num__Fare', 'cat__imputer_cat__Pclass_2',\n",
    "                    'cat__imputer_cat__Pclass_3', 'cat__imputer_cat__Sex_male',\n",
    "                    'cat__imputer_cat__Embarked_Q', 'cat__imputer_cat__Embarked_S',\n",
    "                    'cat__Relative_cat_1-3 relatives', 'cat__Relative_cat_>3 relatives',\n",
    "                    'cat__Age_cat_>15']\n",
    "subset_3_columns = [\"num__imputer_num__Fare\", \"cat__imputer_cat__Pclass_2\",\n",
    "                    \"cat__imputer_cat__Pclass_3\", \"cat__imputer_cat__Sex_male\",\n",
    "                    'cat__imputer_cat__Embarked_Q', 'cat__imputer_cat__Embarked_S',\n",
    "                    'num__imputer_cat__SibSp', 'num__imputer_cat__Parch']\n",
    "\n",
    "base_set = X_train_transformed[base_set_columns]\n",
    "subset_1 = X_train_transformed[subset_1_columns]\n",
    "subset_2 = X_train_transformed[subset_2_columns]\n",
    "subset_3 = X_train_transformed[subset_3_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_FOM_lBMipZ"
   },
   "source": [
    "## Model screening\n",
    "\n",
    "Screening of different models on different subsets of data. Performance is measured by accuracy using k-fold cross-validation.\n",
    "\n",
    "* Support vector classifier\n",
    "* KNN classifier\n",
    "* Random forest\n",
    "* Gradient boosting classifier\n",
    "* Multilayer perceptron (2 layers, 100 neurons each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ts-2YAUc44um",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_screening(X_train, y_train, models, dataset_name=\"\", random_state=42):\n",
    "    \"\"\"\n",
    "    Perform model screening\n",
    "\n",
    "    Parameters:\n",
    "    - X_train: Training data\n",
    "    - y_train: Training labels\n",
    "    - X_val : Validation data\n",
    "    - y_val: Validation labels\n",
    "    - models: A dictionary: {model names: model objects}\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary containing model names and evaluation metrics\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        # Train the model on the training set\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the validation set\n",
    "        #y_pred = model.predict(X_val)\n",
    "\n",
    "        # Calculate evaluation metrics\n",
    "        accuracy = cross_val_score(estimator=model,\n",
    "                                   X=X_train,\n",
    "                                   y=y_train,\n",
    "                                   cv=10,\n",
    "                                   scoring=\"accuracy\")\n",
    "\n",
    "        # Store the evaluation metrics in the results dictionary\n",
    "        results[model_name] = {\n",
    "            dataset_name + \" Accuracy\": 100 * round(np.mean(accuracy), 3),\n",
    "            dataset_name + \" Stdev\": 100 * round(np.std(accuracy), 3)\n",
    "        }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zay1e37u6Mnu",
    "outputId": "15bf321d-c3d9-4fea-9d23-394d110eb0a5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manue\\anaconda3\\envs\\machinelearning\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\manue\\anaconda3\\envs\\machinelearning\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\manue\\anaconda3\\envs\\machinelearning\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create models\n",
    "models = {\"svc_clf\": SVC(),\n",
    "          \"knn_clf\": KNeighborsClassifier(),\n",
    "          \"random_forest_clf\": RandomForestClassifier(),\n",
    "          \"gradient_boosted_clf\": GradientBoostingClassifier(),\n",
    "          \"mlp\": MLPClassifier(hidden_layer_sizes=(100, 100),\n",
    "                               batch_size=32)\n",
    "          }\n",
    "\n",
    "# Train sklearn models and save results for base set\n",
    "results_base = model_screening(X_train=base_set,\n",
    "                               y_train=y_train,\n",
    "                               models=models,\n",
    "                               dataset_name=\"Base set\")\n",
    "\n",
    "# Train sklearn models and save results for subset 1\n",
    "results_subset1 = model_screening(X_train=subset_1,\n",
    "                                  y_train=y_train,\n",
    "                                  models=models,\n",
    "                                  dataset_name=\"Subset 1\")\n",
    "\n",
    "# Train sklearn models and save results for subset 2\n",
    "results_subset2 = model_screening(X_train=subset_2,\n",
    "                                  y_train=y_train,\n",
    "                                  models=models,\n",
    "                                  dataset_name=\"Subset 2\")\n",
    "\n",
    "# Train sklearn models and save results for subset 3\n",
    "results_subset3 = model_screening(X_train=subset_3,\n",
    "                                  y_train=y_train,\n",
    "                                  models=models,\n",
    "                                  dataset_name=\"Subset 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "l9M1N-UE3Y8r",
    "outputId": "a18a464f-07e2-464e-b0d1-e3d1bd2cbcd2",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svc_clf</th>\n",
       "      <th>knn_clf</th>\n",
       "      <th>random_forest_clf</th>\n",
       "      <th>gradient_boosted_clf</th>\n",
       "      <th>mlp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Base set Accuracy</th>\n",
       "      <td>81.4</td>\n",
       "      <td>80.4</td>\n",
       "      <td>81.0</td>\n",
       "      <td>80.9</td>\n",
       "      <td>80.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base set Stdev</th>\n",
       "      <td>2.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subset 1 Accuracy</th>\n",
       "      <td>82.7</td>\n",
       "      <td>81.0</td>\n",
       "      <td>80.5</td>\n",
       "      <td>83.4</td>\n",
       "      <td>80.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subset 1 Stdev</th>\n",
       "      <td>3.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subset 2 Accuracy</th>\n",
       "      <td>82.2</td>\n",
       "      <td>82.2</td>\n",
       "      <td>81.8</td>\n",
       "      <td>83.4</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subset 2 Stdev</th>\n",
       "      <td>3.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subset 3 Accuracy</th>\n",
       "      <td>80.8</td>\n",
       "      <td>79.7</td>\n",
       "      <td>79.1</td>\n",
       "      <td>80.8</td>\n",
       "      <td>80.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subset 3 Stdev</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   svc_clf  knn_clf  random_forest_clf  gradient_boosted_clf  \\\n",
       "Base set Accuracy     81.4     80.4               81.0                  80.9   \n",
       "Base set Stdev         2.9      3.2                4.4                   4.0   \n",
       "Subset 1 Accuracy     82.7     81.0               80.5                  83.4   \n",
       "Subset 1 Stdev         3.9      4.5                5.1                   4.4   \n",
       "Subset 2 Accuracy     82.2     82.2               81.8                  83.4   \n",
       "Subset 2 Stdev         3.3      4.6                4.7                   4.1   \n",
       "Subset 3 Accuracy     80.8     79.7               79.1                  80.8   \n",
       "Subset 3 Stdev         2.5      4.3                5.0                   4.7   \n",
       "\n",
       "                    mlp  \n",
       "Base set Accuracy  80.4  \n",
       "Base set Stdev      2.6  \n",
       "Subset 1 Accuracy  80.7  \n",
       "Subset 1 Stdev      3.6  \n",
       "Subset 2 Accuracy  82.0  \n",
       "Subset 2 Stdev      3.2  \n",
       "Subset 3 Accuracy  80.6  \n",
       "Subset 3 Stdev      4.3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe of results\n",
    "results_base = pd.DataFrame(results_base)\n",
    "results_subset1 = pd.DataFrame(results_subset1)\n",
    "results_subset2 = pd.DataFrame(results_subset2)\n",
    "results_subset3 = pd.DataFrame(results_subset3)\n",
    "\n",
    "# Concatenate dataframes\n",
    "results = pd.concat([results_base, results_subset1,\n",
    "                     results_subset2, results_subset3])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Base set Accuracy</th>\n",
       "      <td>80.82</td>\n",
       "      <td>0.426615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subset 1 Accuracy</th>\n",
       "      <td>81.66</td>\n",
       "      <td>1.304990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subset 2 Accuracy</th>\n",
       "      <td>82.32</td>\n",
       "      <td>0.626099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subset 3 Accuracy</th>\n",
       "      <td>80.20</td>\n",
       "      <td>0.764853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mean       std\n",
       "Base set Accuracy  80.82  0.426615\n",
       "Subset 1 Accuracy  81.66  1.304990\n",
       "Subset 2 Accuracy  82.32  0.626099\n",
       "Subset 3 Accuracy  80.20  0.764853"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate average accuracy and stdev over datasets\n",
    "dataset_accuracies = [\"Base set Accuracy\", \"Subset 1 Accuracy\", \"Subset 2 Accuracy\", \"Subset 3 Accuracy\"]\n",
    "results.loc[dataset_accuracies].agg([\"mean\", \"std\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCHpmzF2rwZr"
   },
   "source": [
    "### Conclusions: Model Screening\n",
    "\n",
    "* In general, all models benefit from the inclusion of relatives and age data.\n",
    "* The three best models are svc, gradient boosting classifier, and mlp on subset 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t82QofzMGo5M"
   },
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_g6oJx_Y5BF0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare datasets for fine tuning\n",
    "X_train = subset_2.astype(\"float32\")\n",
    "y_train = y_train.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTwz6xlDGqP4"
   },
   "source": [
    "### 1. SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1urQwFb1GKH2",
    "outputId": "aa8d7cab-02e8-4903-e3e3-529246cc0e97",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_degree</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.040116</td>\n",
       "      <td>0.011567</td>\n",
       "      <td>0.006261</td>\n",
       "      <td>0.007668</td>\n",
       "      <td>4.951769</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 4.951769101112702, 'class_weight': None,...</td>\n",
       "      <td>0.860335</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.833865</td>\n",
       "      <td>0.019863</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016933</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.007543</td>\n",
       "      <td>0.006997</td>\n",
       "      <td>3.745401</td>\n",
       "      <td>None</td>\n",
       "      <td>14</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 3.745401188473625, 'class_weight': None,...</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.828272</td>\n",
       "      <td>0.019419</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.036989</td>\n",
       "      <td>0.005764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.79691</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 7.796910002727692, 'class_weight': None,...</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.822679</td>\n",
       "      <td>0.021127</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.030722</td>\n",
       "      <td>0.011066</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.007656</td>\n",
       "      <td>3.337086</td>\n",
       "      <td>balanced</td>\n",
       "      <td>2</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 3.337086111390218, 'class_weight': 'bala...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.820451</td>\n",
       "      <td>0.021381</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.018748</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>0.004425</td>\n",
       "      <td>0.006138</td>\n",
       "      <td>6.075449</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 6.075448519014383, 'class_weight': None,...</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.819308</td>\n",
       "      <td>0.022825</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.574566</td>\n",
       "      <td>0.387274</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>0.007357</td>\n",
       "      <td>2.921446</td>\n",
       "      <td>balanced</td>\n",
       "      <td>14</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 2.9214464853521815, 'class_weight': 'bal...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.814826</td>\n",
       "      <td>0.040140</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.024212</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>4.497541</td>\n",
       "      <td>balanced</td>\n",
       "      <td>3</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 4.497541333697656, 'class_weight': 'bala...</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.747191</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.811449</td>\n",
       "      <td>0.037860</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027611</td>\n",
       "      <td>0.007795</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>0.564116</td>\n",
       "      <td>balanced</td>\n",
       "      <td>11</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.5641157902710026, 'class_weight': 'bal...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.735955</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.808110</td>\n",
       "      <td>0.043571</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.012282</td>\n",
       "      <td>0.012072</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>0.006269</td>\n",
       "      <td>6.116532</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 6.116531604882809, 'class_weight': None,...</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.806936</td>\n",
       "      <td>0.015158</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.193261</td>\n",
       "      <td>0.709104</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.003230</td>\n",
       "      <td>1.848545</td>\n",
       "      <td>None</td>\n",
       "      <td>17</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 1.8485445552552704, 'class_weight': None...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.724719</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.800226</td>\n",
       "      <td>0.039810</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.043233</td>\n",
       "      <td>0.022160</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.13265</td>\n",
       "      <td>None</td>\n",
       "      <td>13</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.13264961159866528, 'class_weight': Non...</td>\n",
       "      <td>0.765363</td>\n",
       "      <td>0.735955</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.798016</td>\n",
       "      <td>0.040138</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.027412</td>\n",
       "      <td>0.014125</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.003117</td>\n",
       "      <td>5.142344</td>\n",
       "      <td>balanced</td>\n",
       "      <td>2</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 5.142344384136116, 'class_weight': 'bala...</td>\n",
       "      <td>0.759777</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.790158</td>\n",
       "      <td>0.033946</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.015419</td>\n",
       "      <td>0.003179</td>\n",
       "      <td>0.005250</td>\n",
       "      <td>0.006072</td>\n",
       "      <td>2.123391</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 2.1233911067827616, 'class_weight': 'bal...</td>\n",
       "      <td>0.703911</td>\n",
       "      <td>0.651685</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.657303</td>\n",
       "      <td>0.702580</td>\n",
       "      <td>0.043084</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.013807</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>0.006242</td>\n",
       "      <td>0.007644</td>\n",
       "      <td>3.117111</td>\n",
       "      <td>balanced</td>\n",
       "      <td>9</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 3.1171107608941098, 'class_weight': 'bal...</td>\n",
       "      <td>0.703911</td>\n",
       "      <td>0.646067</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.657303</td>\n",
       "      <td>0.694715</td>\n",
       "      <td>0.043524</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.016943</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.910606</td>\n",
       "      <td>balanced</td>\n",
       "      <td>7</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 3.910606075732408, 'class_weight': 'bala...</td>\n",
       "      <td>0.659218</td>\n",
       "      <td>0.646067</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.691011</td>\n",
       "      <td>0.662921</td>\n",
       "      <td>0.685776</td>\n",
       "      <td>0.044427</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.004428</td>\n",
       "      <td>0.006141</td>\n",
       "      <td>0.012497</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>3.854165</td>\n",
       "      <td>balanced</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 3.854165025399161, 'class_weight': 'bala...</td>\n",
       "      <td>0.659218</td>\n",
       "      <td>0.646067</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.691011</td>\n",
       "      <td>0.657303</td>\n",
       "      <td>0.684653</td>\n",
       "      <td>0.045058</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.016925</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.410255</td>\n",
       "      <td>balanced</td>\n",
       "      <td>6</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 2.410254660260117, 'class_weight': 'bala...</td>\n",
       "      <td>0.709497</td>\n",
       "      <td>0.651685</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.634831</td>\n",
       "      <td>0.651685</td>\n",
       "      <td>0.681225</td>\n",
       "      <td>0.046167</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.019050</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.906064</td>\n",
       "      <td>balanced</td>\n",
       "      <td>18</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 0.906064345328208, 'class_weight': 'bala...</td>\n",
       "      <td>0.648045</td>\n",
       "      <td>0.651685</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.657303</td>\n",
       "      <td>0.673429</td>\n",
       "      <td>0.048427</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015622</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.559945</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 1.5599452033620265, 'class_weight': None...</td>\n",
       "      <td>0.692737</td>\n",
       "      <td>0.629213</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.629213</td>\n",
       "      <td>0.612360</td>\n",
       "      <td>0.673379</td>\n",
       "      <td>0.070565</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.016934</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.912291</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 2.9122914019804194, 'class_weight': None...</td>\n",
       "      <td>0.659218</td>\n",
       "      <td>0.623596</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.634831</td>\n",
       "      <td>0.606742</td>\n",
       "      <td>0.664428</td>\n",
       "      <td>0.068809</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time   param_C  \\\n",
       "15       0.040116      0.011567         0.006261        0.007668  4.951769   \n",
       "0        0.016933      0.002602         0.007543        0.006997  3.745401   \n",
       "1        0.036989      0.005764         0.000000        0.000000   7.79691   \n",
       "3        0.030722      0.011066         0.006251        0.007656  3.337086   \n",
       "11       0.018748      0.006247         0.004425        0.006138  6.075449   \n",
       "8        0.574566      0.387274         0.006658        0.007357  2.921446   \n",
       "19       0.024212      0.005858         0.000821        0.001006  4.497541   \n",
       "4        0.027611      0.007795         0.006247        0.007651  0.564116   \n",
       "6        0.012282      0.012072         0.004729        0.006269  6.116532   \n",
       "18       1.193261      0.709104         0.001615        0.003230  1.848545   \n",
       "12       0.043233      0.022160         0.003125        0.006250   0.13265   \n",
       "10       0.027412      0.014125         0.002020        0.003117  5.142344   \n",
       "5        0.015419      0.003179         0.005250        0.006072  2.123391   \n",
       "17       0.013807      0.003648         0.006242        0.007644  3.117111   \n",
       "16       0.016943      0.002619         0.000000        0.000000  3.910606   \n",
       "13       0.004428      0.006141         0.012497        0.006249  3.854165   \n",
       "14       0.016925      0.002602         0.000000        0.000000  2.410255   \n",
       "9        0.019050      0.000969         0.001228        0.001003  0.906064   \n",
       "2        0.015622      0.000030         0.000000        0.000000  1.559945   \n",
       "7        0.016934      0.002598         0.000000        0.000000  2.912291   \n",
       "\n",
       "   param_class_weight param_degree param_kernel  \\\n",
       "15               None            2         poly   \n",
       "0                None           14          rbf   \n",
       "1                None            6         poly   \n",
       "3            balanced            2         poly   \n",
       "11               None            8          rbf   \n",
       "8            balanced           14         poly   \n",
       "19           balanced            3         poly   \n",
       "4            balanced           11         poly   \n",
       "6                None           11       linear   \n",
       "18               None           17         poly   \n",
       "12               None           13         poly   \n",
       "10           balanced            2       linear   \n",
       "5            balanced            0      sigmoid   \n",
       "17           balanced            9      sigmoid   \n",
       "16           balanced            7      sigmoid   \n",
       "13           balanced            1      sigmoid   \n",
       "14           balanced            6      sigmoid   \n",
       "9            balanced           18      sigmoid   \n",
       "2                None           10      sigmoid   \n",
       "7                None            9      sigmoid   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "15  {'C': 4.951769101112702, 'class_weight': None,...           0.860335   \n",
       "0   {'C': 3.745401188473625, 'class_weight': None,...           0.837989   \n",
       "1   {'C': 7.796910002727692, 'class_weight': None,...           0.815642   \n",
       "3   {'C': 3.337086111390218, 'class_weight': 'bala...           0.798883   \n",
       "11  {'C': 6.075448519014383, 'class_weight': None,...           0.815642   \n",
       "8   {'C': 2.9214464853521815, 'class_weight': 'bal...           0.804469   \n",
       "19  {'C': 4.497541333697656, 'class_weight': 'bala...           0.810056   \n",
       "4   {'C': 0.5641157902710026, 'class_weight': 'bal...           0.782123   \n",
       "6   {'C': 6.116531604882809, 'class_weight': None,...           0.826816   \n",
       "18  {'C': 1.8485445552552704, 'class_weight': None...           0.798883   \n",
       "12  {'C': 0.13264961159866528, 'class_weight': Non...           0.765363   \n",
       "10  {'C': 5.142344384136116, 'class_weight': 'bala...           0.759777   \n",
       "5   {'C': 2.1233911067827616, 'class_weight': 'bal...           0.703911   \n",
       "17  {'C': 3.1171107608941098, 'class_weight': 'bal...           0.703911   \n",
       "16  {'C': 3.910606075732408, 'class_weight': 'bala...           0.659218   \n",
       "13  {'C': 3.854165025399161, 'class_weight': 'bala...           0.659218   \n",
       "14  {'C': 2.410254660260117, 'class_weight': 'bala...           0.709497   \n",
       "9   {'C': 0.906064345328208, 'class_weight': 'bala...           0.648045   \n",
       "2   {'C': 1.5599452033620265, 'class_weight': None...           0.692737   \n",
       "7   {'C': 2.9122914019804194, 'class_weight': None...           0.659218   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "15           0.820225           0.825843           0.808989   \n",
       "0            0.814607           0.825843           0.803371   \n",
       "1            0.792135           0.853933           0.814607   \n",
       "3            0.808989           0.825843           0.808989   \n",
       "11           0.797753           0.825843           0.797753   \n",
       "8            0.741573           0.831461           0.842697   \n",
       "19           0.747191           0.837079           0.803371   \n",
       "4            0.735955           0.825843           0.853933   \n",
       "6            0.808989           0.814607           0.780899   \n",
       "18           0.724719           0.825843           0.814607   \n",
       "12           0.735955           0.820225           0.837079   \n",
       "10           0.752809           0.814607           0.780899   \n",
       "5            0.651685           0.758427           0.741573   \n",
       "17           0.646067           0.769663           0.696629   \n",
       "16           0.646067           0.769663           0.691011   \n",
       "13           0.646067           0.769663           0.691011   \n",
       "14           0.651685           0.758427           0.634831   \n",
       "9            0.651685           0.769663           0.640449   \n",
       "2            0.629213           0.803371           0.629213   \n",
       "7            0.623596           0.797753           0.634831   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "15           0.853933         0.833865        0.019863                1  \n",
       "0            0.859551         0.828272        0.019419                2  \n",
       "1            0.837079         0.822679        0.021127                3  \n",
       "3            0.859551         0.820451        0.021381                4  \n",
       "11           0.859551         0.819308        0.022825                5  \n",
       "8            0.853933         0.814826        0.040140                6  \n",
       "19           0.859551         0.811449        0.037860                7  \n",
       "4            0.842697         0.808110        0.043571                8  \n",
       "6            0.803371         0.806936        0.015158                9  \n",
       "18           0.837079         0.800226        0.039810               10  \n",
       "12           0.831461         0.798016        0.040138               11  \n",
       "10           0.842697         0.790158        0.033946               12  \n",
       "5            0.657303         0.702580        0.043084               13  \n",
       "17           0.657303         0.694715        0.043524               14  \n",
       "16           0.662921         0.685776        0.044427               15  \n",
       "13           0.657303         0.684653        0.045058               16  \n",
       "14           0.651685         0.681225        0.046167               17  \n",
       "9            0.657303         0.673429        0.048427               18  \n",
       "2            0.612360         0.673379        0.070565               19  \n",
       "7            0.606742         0.664428        0.068809               20  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up parameter distributions\n",
    "param_distribs = {\"C\": uniform(0, 10),\n",
    "                  \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "                  \"degree\": randint(0, 20),\n",
    "                  \"class_weight\": [None, \"balanced\"]}\n",
    "\n",
    "# Set up random search\n",
    "rnd_search_svc = RandomizedSearchCV(SVC(),\n",
    "                                    param_distributions=param_distribs,\n",
    "                                    n_iter=20,\n",
    "                                    cv=5,\n",
    "                                    scoring=\"accuracy\",\n",
    "                                    random_state=42)\n",
    "\n",
    "# Fit random search to data set\n",
    "rnd_search_svc.fit(X_train, y_train)\n",
    "\n",
    "# Save tuned classifier\n",
    "svc_clf = rnd_search_svc.best_estimator_\n",
    "\n",
    "# Look at evaluation results\n",
    "cv_results = pd.DataFrame(rnd_search_svc.cv_results_)\n",
    "cv_results.sort_values(by=\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rALLBzoKLviP"
   },
   "source": [
    "### Gradient boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bPHB-VwqI9UD",
    "outputId": "877b02ef-14b3-4759-bf83-aa2cc3d405be",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.269486</td>\n",
       "      <td>0.017025</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>0.156019</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>224</td>\n",
       "      <td>{'learning_rate': 0.15601864044243652, 'loss':...</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.832785</td>\n",
       "      <td>0.021618</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.663988</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.004528</td>\n",
       "      <td>0.005763</td>\n",
       "      <td>0.090606</td>\n",
       "      <td>exponential</td>\n",
       "      <td>572</td>\n",
       "      <td>{'learning_rate': 0.0906064345328208, 'loss': ...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.831680</td>\n",
       "      <td>0.026360</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.435583</td>\n",
       "      <td>0.040437</td>\n",
       "      <td>0.004727</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.020584</td>\n",
       "      <td>exponential</td>\n",
       "      <td>353</td>\n",
       "      <td>{'learning_rate': 0.020584494295802447, 'loss'...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.831680</td>\n",
       "      <td>0.030366</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.387170</td>\n",
       "      <td>0.008285</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.013265</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>325</td>\n",
       "      <td>{'learning_rate': 0.013264961159866528, 'loss'...</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.831649</td>\n",
       "      <td>0.029086</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.041920</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>0.731994</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.7319939418114051, 'loss': ...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.870787</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.830569</td>\n",
       "      <td>0.024875</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.235787</td>\n",
       "      <td>0.009640</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.973756</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>199</td>\n",
       "      <td>{'learning_rate': 0.9737555188414592, 'loss': ...</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.829427</td>\n",
       "      <td>0.020078</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.204748</td>\n",
       "      <td>0.009371</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>0.006096</td>\n",
       "      <td>0.680308</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>176</td>\n",
       "      <td>{'learning_rate': 0.6803075385877797, 'loss': ...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.828328</td>\n",
       "      <td>0.024884</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.205706</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.181825</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>170</td>\n",
       "      <td>{'learning_rate': 0.18182496720710062, 'loss':...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.828316</td>\n",
       "      <td>0.030260</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.349476</td>\n",
       "      <td>0.014495</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.37454</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>280</td>\n",
       "      <td>{'learning_rate': 0.3745401188473625, 'loss': ...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.828310</td>\n",
       "      <td>0.018032</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.470459</td>\n",
       "      <td>0.055522</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.058084</td>\n",
       "      <td>exponential</td>\n",
       "      <td>382</td>\n",
       "      <td>{'learning_rate': 0.05808361216819946, 'loss':...</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.828291</td>\n",
       "      <td>0.023397</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.187138</td>\n",
       "      <td>0.035298</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.601115</td>\n",
       "      <td>exponential</td>\n",
       "      <td>140</td>\n",
       "      <td>{'learning_rate': 0.6011150117432088, 'loss': ...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.827186</td>\n",
       "      <td>0.026965</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.410209</td>\n",
       "      <td>0.008691</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>0.015966</td>\n",
       "      <td>exponential</td>\n",
       "      <td>349</td>\n",
       "      <td>{'learning_rate': 0.015966252220214194, 'loss'...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.870787</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.827186</td>\n",
       "      <td>0.027886</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.031712</td>\n",
       "      <td>0.092138</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.466763</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>828</td>\n",
       "      <td>{'learning_rate': 0.4667628932479799, 'loss': ...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.826075</td>\n",
       "      <td>0.021839</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.532873</td>\n",
       "      <td>0.008283</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.241025</td>\n",
       "      <td>exponential</td>\n",
       "      <td>464</td>\n",
       "      <td>{'learning_rate': 0.24102546602601171, 'loss':...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.826069</td>\n",
       "      <td>0.025625</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.018858</td>\n",
       "      <td>0.053846</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>0.382462</td>\n",
       "      <td>exponential</td>\n",
       "      <td>841</td>\n",
       "      <td>{'learning_rate': 0.38246199126716274, 'loss':...</td>\n",
       "      <td>0.765363</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.821612</td>\n",
       "      <td>0.035536</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.569216</td>\n",
       "      <td>0.015075</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.611853</td>\n",
       "      <td>exponential</td>\n",
       "      <td>485</td>\n",
       "      <td>{'learning_rate': 0.6118528947223795, 'loss': ...</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.821606</td>\n",
       "      <td>0.030835</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.586384</td>\n",
       "      <td>0.015364</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.431945</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>484</td>\n",
       "      <td>{'learning_rate': 0.43194501864211576, 'loss':...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.821574</td>\n",
       "      <td>0.022067</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.901704</td>\n",
       "      <td>0.008858</td>\n",
       "      <td>0.005652</td>\n",
       "      <td>0.003907</td>\n",
       "      <td>0.563288</td>\n",
       "      <td>exponential</td>\n",
       "      <td>786</td>\n",
       "      <td>{'learning_rate': 0.5632882178455393, 'loss': ...</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.819358</td>\n",
       "      <td>0.033408</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.308431</td>\n",
       "      <td>0.016682</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.006048</td>\n",
       "      <td>0.304242</td>\n",
       "      <td>exponential</td>\n",
       "      <td>262</td>\n",
       "      <td>{'learning_rate': 0.3042422429595377, 'loss': ...</td>\n",
       "      <td>0.776536</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.819352</td>\n",
       "      <td>0.026984</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.500635</td>\n",
       "      <td>0.046005</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.832443</td>\n",
       "      <td>exponential</td>\n",
       "      <td>395</td>\n",
       "      <td>{'learning_rate': 0.8324426408004217, 'loss': ...</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.814864</td>\n",
       "      <td>0.028244</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "2        0.269486      0.017025         0.001197        0.001466   \n",
       "12       0.663988      0.012048         0.004528        0.005763   \n",
       "5        0.435583      0.040437         0.004727        0.005556   \n",
       "16       0.387170      0.008285         0.000410        0.000820   \n",
       "1        0.041920      0.006380         0.001309        0.002618   \n",
       "11       0.235787      0.009640         0.000990        0.001250   \n",
       "15       0.204748      0.009371         0.003535        0.006096   \n",
       "7        0.205706      0.009346         0.000399        0.000798   \n",
       "0        0.349476      0.014495         0.000410        0.000819   \n",
       "3        0.470459      0.055522         0.002203        0.003133   \n",
       "4        0.187138      0.035298         0.002005        0.003125   \n",
       "18       0.410209      0.008691         0.002808        0.002945   \n",
       "14       1.031712      0.092138         0.000410        0.000819   \n",
       "19       0.532873      0.008283         0.004606        0.002752   \n",
       "13       1.018858      0.053846         0.005917        0.005190   \n",
       "10       0.569216      0.015075         0.002378        0.001942   \n",
       "9        0.586384      0.015364         0.000798        0.001595   \n",
       "17       0.901704      0.008858         0.005652        0.003907   \n",
       "8        0.308431      0.016682         0.003717        0.006048   \n",
       "6        0.500635      0.046005         0.002130        0.003945   \n",
       "\n",
       "   param_learning_rate   param_loss param_n_estimators  \\\n",
       "2             0.156019     log_loss                224   \n",
       "12            0.090606  exponential                572   \n",
       "5             0.020584  exponential                353   \n",
       "16            0.013265     log_loss                325   \n",
       "1             0.731994     log_loss                 30   \n",
       "11            0.973756     log_loss                199   \n",
       "15            0.680308     log_loss                176   \n",
       "7             0.181825     log_loss                170   \n",
       "0              0.37454     log_loss                280   \n",
       "3             0.058084  exponential                382   \n",
       "4             0.601115  exponential                140   \n",
       "18            0.015966  exponential                349   \n",
       "14            0.466763     log_loss                828   \n",
       "19            0.241025  exponential                464   \n",
       "13            0.382462  exponential                841   \n",
       "10            0.611853  exponential                485   \n",
       "9             0.431945     log_loss                484   \n",
       "17            0.563288  exponential                786   \n",
       "8             0.304242  exponential                262   \n",
       "6             0.832443  exponential                395   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "2   {'learning_rate': 0.15601864044243652, 'loss':...           0.821229   \n",
       "12  {'learning_rate': 0.0906064345328208, 'loss': ...           0.804469   \n",
       "5   {'learning_rate': 0.020584494295802447, 'loss'...           0.804469   \n",
       "16  {'learning_rate': 0.013264961159866528, 'loss'...           0.832402   \n",
       "1   {'learning_rate': 0.7319939418114051, 'loss': ...           0.793296   \n",
       "11  {'learning_rate': 0.9737555188414592, 'loss': ...           0.810056   \n",
       "15  {'learning_rate': 0.6803075385877797, 'loss': ...           0.787709   \n",
       "7   {'learning_rate': 0.18182496720710062, 'loss':...           0.798883   \n",
       "0   {'learning_rate': 0.3745401188473625, 'loss': ...           0.804469   \n",
       "3   {'learning_rate': 0.05808361216819946, 'loss':...           0.821229   \n",
       "4   {'learning_rate': 0.6011150117432088, 'loss': ...           0.804469   \n",
       "18  {'learning_rate': 0.015966252220214194, 'loss'...           0.804469   \n",
       "14  {'learning_rate': 0.4667628932479799, 'loss': ...           0.793296   \n",
       "19  {'learning_rate': 0.24102546602601171, 'loss':...           0.798883   \n",
       "13  {'learning_rate': 0.38246199126716274, 'loss':...           0.765363   \n",
       "10  {'learning_rate': 0.6118528947223795, 'loss': ...           0.770950   \n",
       "9   {'learning_rate': 0.43194501864211576, 'loss':...           0.798883   \n",
       "17  {'learning_rate': 0.5632882178455393, 'loss': ...           0.770950   \n",
       "8   {'learning_rate': 0.3042422429595377, 'loss': ...           0.776536   \n",
       "6   {'learning_rate': 0.8324426408004217, 'loss': ...           0.770950   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "2            0.797753           0.859551           0.848315   \n",
       "12           0.803371           0.865169           0.859551   \n",
       "5            0.814607           0.876404           0.803371   \n",
       "16           0.803371           0.876404           0.797753   \n",
       "1            0.825843           0.870787           0.825843   \n",
       "11           0.803371           0.848315           0.853933   \n",
       "15           0.814607           0.842697           0.859551   \n",
       "7            0.786517           0.865169           0.842697   \n",
       "0            0.808989           0.842697           0.848315   \n",
       "3            0.797753           0.865169           0.814607   \n",
       "4            0.792135           0.848315           0.865169   \n",
       "18           0.814607           0.870787           0.797753   \n",
       "14           0.808989           0.848315           0.848315   \n",
       "19           0.803371           0.853933           0.859551   \n",
       "13           0.797753           0.842697           0.865169   \n",
       "10           0.814607           0.837079           0.865169   \n",
       "9            0.792135           0.837079           0.848315   \n",
       "17           0.792135           0.848315           0.859551   \n",
       "8            0.808989           0.848315           0.848315   \n",
       "6            0.797753           0.825843           0.853933   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "2            0.837079         0.832785        0.021618                1  \n",
       "12           0.825843         0.831680        0.026360                2  \n",
       "5            0.859551         0.831680        0.030366                3  \n",
       "16           0.848315         0.831649        0.029086                4  \n",
       "1            0.837079         0.830569        0.024875                5  \n",
       "11           0.831461         0.829427        0.020078                6  \n",
       "15           0.837079         0.828328        0.024884                7  \n",
       "7            0.848315         0.828316        0.030260                8  \n",
       "0            0.837079         0.828310        0.018032                9  \n",
       "3            0.842697         0.828291        0.023397               10  \n",
       "4            0.825843         0.827186        0.026965               11  \n",
       "18           0.848315         0.827186        0.027886               11  \n",
       "14           0.831461         0.826075        0.021839               13  \n",
       "19           0.814607         0.826069        0.025625               14  \n",
       "13           0.837079         0.821612        0.035536               15  \n",
       "10           0.820225         0.821606        0.030835               16  \n",
       "9            0.831461         0.821574        0.022067               17  \n",
       "17           0.825843         0.819358        0.033408               18  \n",
       "8            0.814607         0.819352        0.026984               19  \n",
       "6            0.825843         0.814864        0.028244               20  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up parameter distributions\n",
    "param_distribs = {\"learning_rate\": uniform(0, 1),\n",
    "                  \"loss\": [\"log_loss\", \"exponential\"],\n",
    "                  \"n_estimators\": randint(10, 1000)}\n",
    "\n",
    "# Set up random search\n",
    "rnd_search_gradient_boost = RandomizedSearchCV(GradientBoostingClassifier(),\n",
    "                                               param_distributions=param_distribs,\n",
    "                                               n_iter=20,\n",
    "                                               cv=5,\n",
    "                                               scoring=\"accuracy\",\n",
    "                                               random_state=42)\n",
    "\n",
    "# Fit random search to data set\n",
    "rnd_search_gradient_boost.fit(X_train, y_train)\n",
    "\n",
    "# Save tuned classifier\n",
    "gradient_boost_clf = rnd_search_gradient_boost.best_estimator_\n",
    "\n",
    "# Look at evaluation results\n",
    "cv_results = pd.DataFrame(rnd_search_gradient_boost.cv_results_)\n",
    "cv_results.sort_values(by=\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gRDHaTZBMbkj"
   },
   "source": [
    "### MLP\n",
    "\n",
    "For the neural network model, the data set is divided into a validation set to avoid time-consuming cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "8blWBsndMdPs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data into train and validation set\n",
    "X_mlp_train, X_mlp_val, y_mlp_train, y_mlp_val = train_test_split(X_train,\n",
    "                                                                  y_train,\n",
    "                                                                  train_size=0.8,\n",
    "                                                                  random_state=42)\n",
    "\n",
    "# Create batched and prefetched tensorflow datasets\n",
    "mlp_train_ds = tf.data.Dataset.from_tensor_slices((X_mlp_train, y_mlp_train))\n",
    "mlp_train_ds = mlp_train_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "mlp_val_ds = tf.data.Dataset.from_tensor_slices((X_mlp_val, y_mlp_val))\n",
    "mlp_val_ds = mlp_val_ds.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ZhfipsAFMaMw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int(\"units\", min_value=8, max_value=512, step=8)\n",
    "  hp_activation = hp.Choice(\"activation\",\n",
    "                            values=[\"relu\", \"elu\", \"selu\", \"gelu\"])\n",
    "  model.add(keras.layers.Dense(units=hp_units, activation=hp_activation,\n",
    "                               kernel_initializer=\"he_normal\"))\n",
    "  model.add(keras.layers.Dense(units=hp_units, activation=hp_activation,\n",
    "                               kernel_initializer=\"he_normal\"))\n",
    "  model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  hp_learning_rate = hp.Choice(\"learning_rate\", values=list(np.linspace(0, 0.1)))\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.losses.BinaryCrossentropy(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "svGvqEyMNs6g",
    "outputId": "7cd30407-ec45-4339-a27a-a6b75d42d655",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 03s]\n",
      "val_accuracy: 0.832402229309082\n",
      "\n",
      "Best val_accuracy So Far: 0.8379888534545898\n",
      "Total elapsed time: 00h 01m 02s\n"
     ]
    }
   ],
   "source": [
    "# Set up Keras hypertuner using Hyperband for searching\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective=\"val_accuracy\",\n",
    "                     max_epochs=20,\n",
    "                     factor=3,\n",
    "                     directory=\"mlp_finetuning\",\n",
    "                     project_name=\"fine_tuning6\")\n",
    "\n",
    "tuner.search(mlp_train_ds,\n",
    "             validation_data=mlp_val_ds,\n",
    "             epochs=20)\n",
    "\n",
    "# Print best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w3atsybRnbbX",
    "outputId": "17420d41-a9f6-4da0-da70-4d387b550272",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Units: 352\n",
      "Activation: relu\n",
      "Learning rate: 0.02448979591836735\n"
     ]
    }
   ],
   "source": [
    "# Print best hyperparameters\n",
    "best_units = tuner.get_best_hyperparameters(num_trials=1)[0].get(\"units\")\n",
    "best_activation = tuner.get_best_hyperparameters(num_trials=1)[0].get(\"activation\")\n",
    "best_lr = tuner.get_best_hyperparameters(num_trials=1)[0].get(\"learning_rate\")\n",
    "print(f\"Units: {best_units}\")\n",
    "print(f\"Activation: {best_activation}\")\n",
    "print(f\"Learning rate: {best_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o-psXiQgIiKL",
    "outputId": "2359c10d-2af7-4812-a61e-b5ef2a204ab2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1.7689 - accuracy: 0.6840 - val_loss: 0.4800 - val_accuracy: 0.7709 - lr: 0.0245\n",
      "Epoch 2/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4510 - accuracy: 0.8258 - val_loss: 0.4623 - val_accuracy: 0.8156 - lr: 0.0245\n",
      "Epoch 3/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.8258 - val_loss: 0.4278 - val_accuracy: 0.8212 - lr: 0.0245\n",
      "Epoch 4/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3898 - accuracy: 0.8343 - val_loss: 0.4272 - val_accuracy: 0.8212 - lr: 0.0245\n",
      "Epoch 5/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3836 - accuracy: 0.8371 - val_loss: 0.4195 - val_accuracy: 0.8212 - lr: 0.0245\n",
      "Epoch 6/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3826 - accuracy: 0.8315 - val_loss: 0.4166 - val_accuracy: 0.8212 - lr: 0.0245\n",
      "Epoch 7/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3807 - accuracy: 0.8315 - val_loss: 0.4143 - val_accuracy: 0.8212 - lr: 0.0245\n",
      "Epoch 8/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.8329 - val_loss: 0.4115 - val_accuracy: 0.8212 - lr: 0.0245\n",
      "Epoch 9/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.8315 - val_loss: 0.4107 - val_accuracy: 0.8324 - lr: 0.0245\n",
      "Epoch 10/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3793 - accuracy: 0.8329 - val_loss: 0.4195 - val_accuracy: 0.8156 - lr: 0.0245\n",
      "Epoch 11/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3808 - accuracy: 0.8301 - val_loss: 0.4181 - val_accuracy: 0.8268 - lr: 0.0245\n",
      "Epoch 12/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.8385 - val_loss: 0.4183 - val_accuracy: 0.8324 - lr: 0.0245\n",
      "Epoch 13/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3681 - accuracy: 0.8357 - val_loss: 0.4210 - val_accuracy: 0.8268 - lr: 0.0245\n",
      "Epoch 14/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3707 - accuracy: 0.8315 - val_loss: 0.4148 - val_accuracy: 0.8268 - lr: 0.0245\n",
      "Epoch 15/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3503 - accuracy: 0.8441 - val_loss: 0.4247 - val_accuracy: 0.8101 - lr: 0.0024\n",
      "Epoch 16/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3469 - accuracy: 0.8455 - val_loss: 0.4275 - val_accuracy: 0.8101 - lr: 0.0024\n",
      "Epoch 17/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3458 - accuracy: 0.8455 - val_loss: 0.4266 - val_accuracy: 0.8101 - lr: 0.0024\n",
      "Epoch 18/1000\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3449 - accuracy: 0.8455 - val_loss: 0.4265 - val_accuracy: 0.8045 - lr: 0.0024\n",
      "Epoch 19/1000\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3443 - accuracy: 0.8469 - val_loss: 0.4266 - val_accuracy: 0.8045 - lr: 0.0024\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4107 - accuracy: 0.8324\n",
      "Validation accuracy: 0.832\n"
     ]
    }
   ],
   "source": [
    "# Get the best hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build mlp classifier with best hyperparameters\n",
    "mlp_clf = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Build early stopping and reduce plateau callbacks\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "\n",
    "# Train mlp classifier\n",
    "history = mlp_clf.fit(mlp_train_ds,\n",
    "                      validation_data=mlp_val_ds,\n",
    "                      epochs=1000,callbacks=[early_stopping_cb, lr_plateau_cb])\n",
    "\n",
    "# Calculate accuracy for validation set\n",
    "print(f\"Validation accuracy: {mlp_clf.evaluate(mlp_val_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3BIsE9w-yhDJ"
   },
   "source": [
    "## Prediction of test data by each model and submission to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZJ7Lq24Xy0XW",
    "outputId": "d0db683e-75cb-41c7-9ff7-8c164bf15cb1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Transform test dataset\n",
    "X_test = titanic_transformation(test_dataset)\n",
    "\n",
    "# Filter columns to match with subset 2\n",
    "X_test = X_test[subset_2_columns]\n",
    "X_test.astype(\"float32\")\n",
    "\n",
    "# Predict survival based on the test set\n",
    "y_pred_svc = svc_clf.predict(X_test).astype(\"int64\")\n",
    "y_pred_boost = gradient_boost_clf.predict(X_test).astype(\"int64\")\n",
    "y_pred_mlp = tf.round(mlp_clf.predict(X_test))\n",
    "y_pred_mlp = tf.cast(tf.squeeze(y_pred_mlp), tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "6eMMar2K1hw2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take passengerId as series from test_dataset_copy\n",
    "passenger_ids = test_dataset_copy[\"PassengerId\"]\n",
    "\n",
    "# Create dataframes with PassengerId and Survived as columns\n",
    "svc_submission = pd.DataFrame({\"PassengerId\": passenger_ids,\n",
    "                               \"Survived\": y_pred_svc})\n",
    "boost_submission = pd.DataFrame({\"PassengerId\": passenger_ids,\n",
    "                               \"Survived\": y_pred_boost})\n",
    "mlp_submission = pd.DataFrame({\"PassengerId\": passenger_ids,\n",
    "                               \"Survived\": y_pred_mlp})\n",
    "\n",
    "# Write csv files for submission\n",
    "svc_submission.to_csv(\"svc_submission.csv\", index=False)\n",
    "boost_submission.to_csv(\"boost_submission.csv\", index=False)\n",
    "mlp_submission.to_csv(\"mlp_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GO2SuaNgEnoe"
   },
   "source": [
    "**Scores from Kaggle**:\n",
    "* MLP: 0.76315\n",
    "* GradientBoost: 0.76794\n",
    "* SVC: 0.78229"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
